{
  "author": {
    "name": "Aron Kornhall",
    "email": "aron@optimalbits.com",
    "url": "http://optimalbits.com"
  },
  "name": "crawlme",
  "description": "Makes your ajax web application indexable by search engines by generating html snapshots on the fly. Caches results for blazing fast responses and better page ranking.",
  "keywords": [
    "ajax",
    "crawling",
    "google",
    "indexing",
    "SEO",
    "Search Engine Optimization"
  ],
  "version": "0.0.6",
  "main": "./index.js",
  "engines": {
    "node": ">=0.6.10"
  },
  "dependencies": {
    "zombie": "2.x.x",
    "lru-cache": "2.3.x",
    "async": "0.2.6"
  },
  "devDependencies": {
    "connect": "2.x.x",
    "express": "3.x.x",
    "mocha": "1.6.x",
    "request": "2.11.x",
    "should": "1.2.x"
  },
  "scripts": {
    "test": "mocha --reporter spec --bail"
  },
  "readme": "#Crawlme\nA Connect/Express middleware that makes your node.js web application indexable by search engines. Crawlme generates static HTML snapshots of your JavaScript web application on the fly and has a built in periodically refreshing in-memory cache, so even though the snapshot generation may take a second or two, search engines will get them really fast. This is beneficial for SEO since response time is one of the factors used in the page rank algorithm.\n\nMaking ajax applications crawlable has always been tricky since search engines don't execute the JavaScript on the web sites they crawl. The solution to this is to provide the search engines with pre-rendered HTML versions of each page on your site, but creating those HTML versions has until now been a tedious and error prone process with many manual steps. Crawlme fixes this by rendering HTML snapshots of your web application on the fly whenever the Googlebot crawls your site. Apart from making the process of more or less manually creating indexable HTML versions of your site obsolete, this also has the benefit that Google will always index the latest version of your site and not some old pre-rendered version.\n\nFollow [optimalbits](http://twitter.com/optimalbits) for news and updates regarding this library.\n\n##How to use\n1. Make you ajax app use the hashbang #! instead of just the # in urls. This tells Google that those urls support ajax crawling and indexing.\n2. Insert the Crawlme middleware before your server in the chain of Connect/Express middlewares.\n3. Sit back and relax. Crawlme takes care of the rest. :)\n\n##Example\n    var\n      connect = require('connect'),\n      http = require('http'),\n      crawlme = require('crawlme');\n\n    var app = connect()\n      .use(crawlme())\n      .use(connect.static(__dirname + '/webroot'));\n\n    http.createServer(app).listen(3000);\n\n##Install\n    npm install crawlme\n\n##How it works\nGoogle detects that your page *your.server.com/page.html#!key=value* is ajax-crawlable by the hashbang #! in the url. The Googlebot doesn't evaluate JavaScript so it can't index the page directly. Instead it tries to get the URL *your.server.com/page.html?_escaped_fragment_=key=value* and expects to find an HTML snapshot of your page there. Crawlme will catch all requests to this kind of URLs and generate a HTML snapshot of the original ajax page on the fly.\n\nMore info on Google's ajax crawling can be found [here](https://developers.google.com/webmasters/ajax-crawling/docs/getting-started)\n\n##Test\n###Running the unit tests\n1. Install dev-dependencies\n    npm install\n2. Run the test suite\n    npm test\n\n###Testing that your ajax web application is crawlable\nPick an ajax url to some part of your web application like for example *your.server.com/page.html#!key=value*\nNow replace the hashbang with *?_escaped_fragment_=*. The new URL will be *your.server.com/page.html?_escaped_fragment_=key=value*\nNow go to that URL. Crawlme should intercept the request and render an HTML snapshot of your page.\n\nYou can also use Googles [Fetch as Googlebot](http://www.google.com/support/webmasters/bin/answer.py?hl=en&answer=158587) tool.\n\n##Reference\n\n    crawlme(options)\n\n__Arguments__\n \n    options  {Object} options object\n    \n##Options\nCrawlme provides the following configuration options:\n- `waitFor`   The time (in ms) crawlme waits before it assumes that your ajax page has finished loading and takes an HTML snapshot. Set this high enough to make sure that your page loads completely before the snapshot is taken. Defaults to 1000ms.\n- `protocol`  The protocol crawlme should use to get the ajax pages. If crawlme runs under express this is determined automatically. Under connect this option is used. (defaults to http)\n- `cacheSize`  The size of the cache that crawlme should use to cache the snapshots. String.prototype.length is used to determine the \"size\" of each snapshot. A cache size of 0 means no cache. Defaults to 2^20.\n- `cacheRefresh`  The number of seconds between cache refreshes. Defaults to 15 minutes.\n\n##Under the hood\nCrawlme uses the excellent headless browser [zombie.js](http://zombie.labnotes.org/) to render the HTML snapshots.\n\n##License \n\n(The MIT License)\n\nCopyright (c) 2012 Optimal Bits Sweden AB (http://optimalbits.com)\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n'Software'), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
  "readmeFilename": "README.md",
  "_id": "crawlme@0.0.6",
  "dist": {
    "shasum": "1037c78954cb08b449b495e7902c2bd6815298fb"
  },
  "_from": "crawlme@",
  "_resolved": "https://registry.npmjs.org/crawlme/-/crawlme-0.0.6.tgz"
}
